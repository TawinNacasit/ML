{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "# !pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"./cats_vs_dogs\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=1234).select(range(100)) # ðŸ¤”\n",
    "dataset = dataset.train_test_split(test_size=0.3, seed=1234) # ðŸ¤”\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# !pip install transformers\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"microsoft/resnet-50\" # ðŸ¤”\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor # ðŸ¤”\n",
    "\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "size = image_processor.size[\"shortest_edge\"] if \"shortest_edge\" in image_processor.size else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize]) # ðŸ¤”\n",
    "\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "\n",
    "dataset = dataset.with_transform(transforms)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0][\"pixel_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray[tune]\n",
    "\n",
    "from ray import tune \n",
    "\n",
    "def ray_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n",
    "        \"per_device_train_batch_size\": tune.choice([1, 2, 3]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate\n",
    "# !pip install evaluate\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer, DefaultDataCollator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# model = AutoModelForImageClassification.from_pretrained(\n",
    "#     checkpoint,\n",
    "#     num_labels=len(labels),\n",
    "#     id2label=id2label,\n",
    "#     label2id=label2id,\n",
    "#     ignore_mismatched_sizes=True,\n",
    "# )\n",
    "\n",
    "def model_init(trial):\n",
    "    return AutoModelForImageClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_labels=len(labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True,\n",
    "    )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_image_model\", # ðŸ¤”\n",
    "    remove_unused_columns=False,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", # ðŸ¤”\n",
    "    learning_rate=1e-5, # ðŸ¤”\n",
    "    per_device_train_batch_size=1, # ðŸ¤”\n",
    "    gradient_accumulation_steps=1, # ðŸ¤”\n",
    "    per_device_eval_batch_size=1, # ðŸ¤”\n",
    "    num_train_epochs=1, # ðŸ¤”\n",
    "    warmup_ratio=0.1, # ðŸ¤”\n",
    "    logging_steps=10, # ðŸ¤”\n",
    "    load_best_model_at_end=True, # ðŸ¤”\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=None,\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# trainer.train()\n",
    "# trainer.save_model(\"my_final_image_model\") # ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    backend=\"ray\",\n",
    "    hp_space=ray_hp_space,\n",
    "    n_trials=10,\n",
    ")\n",
    "\n",
    "# Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\n",
    "# LongPathsEnabled -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=\"./cats_vs_dogs\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset[\"train\"][\"image\"][1] # ðŸ¤”\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model=\"./my_final_image_model\")\n",
    "classifier(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
